[["index.html", "Environmental sensor data management and analysis with R Preface 0.1 Who is this book for? 0.2 How should I read this book? 0.3 What is WildTrax? 0.4 Why did you build wildRtrax? 0.5 Impact and intentions 0.6 Installing the package 0.7 Usage 0.8 Acknowledgements", " Environmental sensor data management and analysis with R Alexander G. MacPhail, Marcus Becker, Elly C. Knight 2023-03-15 Preface wildRtrax (pronounced ‘wilder tracks’) is an R package to help environmental sensor data users to create full-cycle work flows from data management to analytics. 0.1 Who is this book for? This book is a valuable resource for anyone working with environmental sensor data and seeking to manage it using R. It is suitable for both experienced users and those new to the subject, as it is written in a clear and accessible style. While the book is designed to be user-friendly, it also contains advanced concepts and functions that may require additional reading to fully understand. The authors encourage readers to engage and provide feedback, as the book and work flows will continue to evolve with the software. The content relies on understand of the following R packages: tidyverse mainly dplyr and purrr for data tidying and functional programming fs for file system operations lubridate for dealing with dates and times sf for simple features mapping 0.2 How should I read this book? For any given environmental sensor, the general workflow is outlined below and how this book fits into the bigger picture of environmental sensor data management. To effectively use this book to manage environmental sensor data, follow these steps: Understanding the basics Collecting data Data pre-processing Data processing and verification using WildTrax Data analysis Reporting Keep the following tips in mind as well: Start with the basics and build upon them as you progress through the book. Use the sidebar menu to guide your reading and keep you organized Review the information periodically to reinforce your understanding and keep the information fresh in your mind The Did you know? sections will provide additional information about a function or work flow. The Keep in mind sections will warn you when there is something you should think about before running a function or designing a study, for example. 0.3 What is WildTrax? WildTrax is a web-enabled portal designed to manage, store, process, share and discover environmental sensor data and the biological data extracted from the media. WildTrax was developed by the Alberta Biodiversity Monitoring Institute. wildRtrax serves as a parallel design and indicator to WildTrax for future analytics and functionalities. 0.4 Why did you build wildRtrax? By outlining a standardized and harmonized procedure for data intake, quality control, processing and verification of acoustic data from autonomous recording units (ARUs), wildRtrax and WildTrax hope to provide open work flows for using ARUs to answer meaningful biological questions in order to inform conservation and decision-making. Developing parallel-track design between an R package and a web-enabled software like WildTrax can significantly improve the software development process. It allows for simultaneous development and testing of both applications, reducing the chances of errors and incompatibilities, and formalizing data structures and APIs across a network of different applications. 0.5 Impact and intentions wildRtrax strives to maintain independent, scientifically credible, relevant, accessible, and transparent language and code. By doing so, we hope to provide unbiased and accurate information products that are easily understood by anyone. Our values are grounded in leadership, accuracy, ingenuity, passion, personal initiative and teamwork in the field of environmental sensor data as we seek to inspire users to engage in responsible resource management. Our team values personal initiative and teamwork, and we encourage learning, feedback, to its shared success. We are passionate about our work and the impact it has on the environment, and we continuously work to fuel better products and processes through innovative ideas. You can visit the Alberta Biodiversity Monitoring Institute for more information. 0.6 Installing the package You can install wildRtrax directly from this repository with: install.packages(&quot;remotes&quot;) remotes::install_github(&quot;ABbiodiversity/wildRtrax&quot;) Or the development version with: remotes::install_github(&quot;ABbiodiversity/wildRtrax@development&quot;) 0.7 Usage All functions begin with a wt_* prefix. Column names and metadata align with the WildTrax infrastructure. The goal is to follow the work flow of pre-processing, linking with WildTrax, download and analysis. 0.8 Acknowledgements The Alberta Biodiversity Monitoring Institute supports and funds all operations surrounding wildRtrax and WildTrax. Many thanks to Dr. Richard Hedley for providing the basis for the wt_wac_info internal function for wac file support. "],["1-introduction.html", "Chapter 1 Introduction 1.1 Environmental sensors 1.2 Open data 1.3 Biological metrics 1.4 Standardizing information pipelines", " Chapter 1 Introduction 1.1 Environmental sensors Environmental sensors are devices used to measure and record various environmental parameters, such as temperature, humidity, pressure, light, and sound. These sensors can be used to monitor changes in the environment over time and provide valuable information about the conditions that wildlife species experience in their habitats. In wildlife ecology, environmental sensors are commonly used to study the behavior, habitat preferences, and distribution of wildlife species. For example, temperature sensors can be used to monitor the microclimate of an animal’s habitat and determine the effects of temperature on its behavior and physiology. Humidity sensors can be used to study the impact of moisture on the distribution and abundance of species in different ecosystems. Sound sensors, principally, autonomous recording units (or ARUs) can be used to detect and identify the vocalizations of animals, allowing researchers to study communication patterns, behavior, population size, density, habitat preference, movement and many other biological metrics. Wildlife cameras, also known as trail cameras or remote cameras, capture images and videos of animals in their natural habitats, providing researchers with valuable information on behavior, population dynamics, habitat use, and other biological metrics. Environmental sensors can also be used to monitor changes in the environment caused by human activities, such as deforestation, pollution, and climate change. By measuring and recording changes in environmental conditions, researchers can better understand the impact of these activities on wildlife species and develop effective conservation strategies to protect them. 1.2 Open data Open data refers to data that is freely available for anyone to access, use, and share. Open data is important in the context of environmental sensors because it allows researchers, scientists, and policymakers to access and use data collected by sensors to gain insights into environmental conditions and make informed decisions. Environmental sensors generate large amounts of data on various environmental parameters such as audio recordings and images. By making this data openly available, researchers can analyze it to gain insights into patterns and trends over time, leading to a better understanding of environmental conditions and the impact of human activities on the environment. Open data also promotes transparency and accountability in environmental research. It allows the public to access and understand the data used to inform decisions about environmental management and conservation. Additionally, open data can lead to the development of innovative solutions and technologies that can help address environmental challenges. Open data also helps promote reproducibility ensuring independent verification of the data. Reproducibility ensures that the methods used to collect and analyze the data are transparent and can be independently verified by other researchers, ensuring that the results are reliable and accurate, establishing scientific validity. 1.3 Biological metrics Biological metrics are measurements used to evaluate the health and function of ecosystems. They include measures of biodiversity, abundance, and other ecological parameters such as population density, community composition, and functional traits of species. To ensure effective environmental monitoring programs, it is crucial to select appropriate biological metrics that align with the specific goals and objectives of the program. Feasibility and efficiency of data collection and analysis are also important factors to consider. Using well-established and widely used biological metrics can enhance comparability of results across different data sets, studies, and regions. Long-term monitoring is essential for detecting trends and early warning signs of potential environmental problems. Therefore, selecting metrics that are sensitive to changes over time and that can be measured consistently over a long period is essential. The time and resources required for data collection and analysis must be considered when selecting biological metrics as some may require more time and resources than others, while some may be easier to interpret and communicate to stakeholders. 1.4 Standardizing information pipelines Standardized workflows can help with environmental sensor data by ensuring that data is collected, processed, and analyzed in a consistent and transparent manner. This helps to ensure that the data is reliable and accurate, and can be easily compared and combined with other data sets. Standardized workflows typically involve a series of steps that are designed to ensure that data is collected and analyzed consistently across different research projects and sites. These steps may include: Pre-processing: Cleaning and filtering the raw sensor data to remove any noise or errors. Quality control: Checking the data for outliers or errors, and making corrections or adjustments as necessary. Processing: Transforming and extracting species from the raw sensor data Verification: Ensuring the species detections are correct Analysis: This step involves applying statistical or other analytical methods to the data to extract meaningful insights or calculate biological metrics. Reporting: Presenting the results of the analysis in a clear and understandable format, such as charts, graphs or tabular data. By standardizing these workflows, researchers can ensure that data is collected and analyzed consistently across different projects and organizations, reducing the risk of errors or inconsistencies. This helps to ensure that the data is reliable and accurate, and can be used to inform decisions related to environmental management and conservation. In addition, standardized workflows can facilitate data sharing and collaboration among researchers, as it ensures that data is collected and processed in a manner that is consistent with best practices and widely accepted standards. This can help to promote data integration and interoperability, enabling researchers to combine data from different sources to gain a more comprehensive understanding of environmental conditions and the impact of human activities on the environment. "],["2-acoustic-data-pre-processing.html", "Chapter 2 Acoustic data pre-processing 2.1 Acoustic data management basics 2.2 Manipulating recordings 2.3 Other convenience functions: distance between locations 2.4 Using acoustic indices and LDFCs 2.5 Linking acoustic data to WildTrax", " Chapter 2 Acoustic data pre-processing 2.1 Acoustic data management basics The first step after an ARU is retrieved from the field is to promptly download and secure the data to create a redundant backup. Having redundant backups not only protects against data loss but also ensures business continuity and minimizes downtime in the event of a system failure or natural disaster. Furthermore, in case there is an issue with the SD card copy during the quality control process, having a redundant backup ensures that a copy of the data can be restored. 2.1.1 Acoustic metadata In wildRtrax and WildTrax, there are a few essential components and standards that are required in order for the data to be utilized within this context: Location: The physical, geographic place at which environmental sensors were deployed and/or biological data was collected on the landscape. This is how you would associate spatial coordinates to the raw audio data. Date and time: The temporal component of the audio recording - when the recording took place. Many time formats are possible but the recommended standard is YYYYMMDD Sample rate: The frequency at which audio waveforms are captured during analog-to-digital conversion in the environment. Digital audio uses pulse-code modulation and digital signals for sound reproduction, allowing signals to be stored, retrieved and transmitted without any loss of quality. Sampling rates of 44.1 kHz, 48 kHz, or 96 kHz are commonly used for capturing audio within the 20–20,000 Hz range. Higher sampling rates (&gt;96 kHz) are employed to capture ultrasonic species as needed. A recording is the raw media or audio file. The following data types are supported within wildRtrax package. They are implicitly related to how each model and type of ARU records data. See Wildlife Acoustics, Frontier Labs and Open Acoustic Devices for examples to learn more. ABMI-1025-SW ABMI-1025-SW_20220406_074500.{wav,wac,flac,mp3} ABMI-1025-SW_0+1_20220406_074500 Some additional file name recommendations include: Omitting leading zeros for numeric delimited content, e.g. use OG-1-3-5 instead of OG-01-003-05, unless they serve a identification purpose, e.g. 3-0-A12 where -0- indicates the an absence of a treatment Metadata are also supported for .dump, .txt, .csv, .fls, and .SM4S files Delimiters such as “-”, “_”, “@” are supported Location name strings that appear numeric (35001) should be treated with caution when importing via csv Spaces and slashes “/” “” in location names are not supported “_000” suffixes from Wildlife Acoustics Kaleidoscope output (wac -&gt; wav conversion) are supported Audio files need to contain both spatial and temporal information which is the minimum required in order to upload media to WildTrax, e.g. ABMI-538-SW_20220506_050000, where ABMI-538-SW is the location and 20220506_050000 is the timestamp. Both these pieces of information can tell you when and where the recording took place. 2.1.2 Acoustic file types wac are proprietary, lossless compressed file formats developed by Wildlife Acoustics wav is the standard, ubiquitous uncompressed audio file format mp3 a lossy compressed audio file format; works by reducing the accuracy of certain sound components, and eliminating others flac is a lossless compressed audio file format Did you know? When data are uploaded to WildTrax, the audio is converted and stored as flac. 2.2 Manipulating recordings Monitoring programs often generate an enormous amount of audio data that exceeds human capacity to listen to. To overcome this challenge, we can select specific audio files for upload to WildTrax and processing using predetermined criteria. This approach not only prioritizes important data but also helps minimize data storage costs while maximizing processing power for calculating relevant biological metrics. Keep in mind If you’re not an R user you can stop here and upload all of your recordings directly an organization on WildTrax. WildTrax however does not contain all the necessary data quality control measures to uptake data that are included in wildRtrax. Go to the organization on WildTrax Go to Manage &gt; Upload Recordings to Organization Follow the steps in WildTrax to finalize data upload 2.2.1 Reading files The first step in data pre-processing is to determine what files exist. wt_audio_scanner is the function that provides the basis for the rest of the data pre-processing steps. The function recursively scans directories of audio data and returns standard metadata such as the file path, file name, file size, date, time, location name, that will later be used in WildTrax. files &lt;- wt_audio_scanner(path = &quot;../ABMI/ARU/ABMI-EH/2022/V1/228/228-NE&quot;, file_type = &quot;wav&quot;, extra_cols = F) &gt; head(files) # A tibble: 6 × 11 file_path size_Mb unsafe file_…¹ locat…² recording_date_time file_…³ julian year gps_e…⁴ time_…⁵ &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;int&gt; 1 /volumes/budata/abmi/a… 3.51 Safe 228-NE… 228-NE 2021-11-21 12:35:49 wav 325 2021 NA 1 2 /volumes/budata/abmi/a… 106. Safe 228-NE… 228-NE 2022-03-01 00:00:00 wav 60 2022 NA 1 3 /volumes/budata/abmi/a… 31.8 Safe 228-NE… 228-NE 2022-03-01 02:00:00 wav 60 2022 NA 2 4 /volumes/budata/abmi/a… 106. Safe 228-NE… 228-NE 2022-03-01 08:59:00 wav 60 2022 NA 3 5 /volumes/budata/abmi/a… 31.8 Safe 228-NE… 228-NE 2022-03-01 10:29:00 wav 60 2022 NA 4 6 /volumes/budata/abmi/a… 31.8 Safe 228-NE… 228-NE 2022-03-01 12:00:00 wav 60 2022 NA 5 # … with abbreviated variable names ¹ file_name, ² location, ³ file_type, ⁴ gps_enabled, ⁵ time_index The columns from wt_audio_scanner are generated from the raw media file name in order to associate a file prefix to a location, the time stamp to a date and time, and so on. Did you know? Directories of acoustic data at the ABMI are organized in the following hierarchy. Organization: The institution or organization the data belongs to Sensor type: ARU Project: A project is a grouping of locations and recordings designed to answer an ecologically relevant question. Such programs at the ABMI include, Ecosystem Health (ABMI-EH), Before-After Dose Response (BADR). with location naming conventions such as ABMI-1025-SW and 2-0-A117, respectively. Deployment Year: The year the data was collected. Repeat visits of locations are defined in the year for things like trend data sets. Visit: A unique sequential key to define the year and visit the media collection took place, e.g. V1, V2, etc. Group: Is the delimited name of a location. It is aggregated in order to represent spatial relationships or clustering within the field project. (e.g. ABMI-1025-SW is the location but ABMI-1025 is the group given it defines a specific clustering of locations for the study design) Location: is the joining key to WildTrax and also the base directory to the media You can choose extra_cols = T you’ll be supplied with additional columns that can be used to help select recordings, specifically sample rate, length (seconds) and number of channels. files_extra &lt;- wt_audio_scanner(path = ../ABMI/ARU/ABMI-EH/2022/V1/228/228-NE&quot;, file_type = &quot;wav&quot;, extra_cols = T) &gt; files_extra # A tibble: 1,041 × 14 file_path size_Mb file_…¹ locat…² recording_date_time file_…³ julian year gps_e…⁴ time_…⁵ lengt…⁶ sampl…⁷ &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; 1 /volumes/bud… 3.51 228-NE… 228-NE 2021-11-21 12:35:49 wav 325 2021 NA 1 19.9 44100 2 /volumes/bud… 106. 228-NE… 228-NE 2022-03-01 00:00:00 wav 60 2022 NA 1 600 44100 3 /volumes/bud… 31.8 228-NE… 228-NE 2022-03-01 02:00:00 wav 60 2022 NA 2 180 44100 4 /volumes/bud… 106. 228-NE… 228-NE 2022-03-01 08:59:00 wav 60 2022 NA 3 600 44100 5 /volumes/bud… 31.8 228-NE… 228-NE 2022-03-01 10:29:00 wav 60 2022 NA 4 180 44100 6 /volumes/bud… 31.8 228-NE… 228-NE 2022-03-01 12:00:00 wav 60 2022 NA 5 180 44100 7 /volumes/bud… 31.8 228-NE… 228-NE 2022-03-01 15:00:00 wav 60 2022 NA 6 180 44100 8 /volumes/bud… 31.8 228-NE… 228-NE 2022-03-01 18:17:00 wav 60 2022 NA 7 180 44100 9 /volumes/bud… 31.8 228-NE… 228-NE 2022-03-01 20:17:00 wav 60 2022 NA 8 180 44100 10 /volumes/bud… 106. 228-NE… 228-NE 2022-03-02 00:00:00 wav 61 2022 NA 1 600 44100 # … with 1,031 more rows, 2 more variables: n_channels &lt;dbl&gt;, unsafe &lt;chr&gt;, and abbreviated variable names # ¹ file_name, ² location, ³ file_type, ⁴ gps_enabled, ⁵ time_index, ⁶ length_seconds, ⁷ sample_rate Keep in mind Using the file name and file path from the output of wt_audio_scanner will determine what the location name and time stamp of the recording will be. If you notice that the location name or time stamp is incorrect, you should re-visit the raw audio and determine if it is correct. See the section Linking acoustic data to WildTrax for more information. 2.2.2 Segmenting audio files It’s possible that recordings are longer than the maximum length WildTrax can currently import (1800 seconds or 320MB). In this case, you can use wt_chop to create intervals of recordings. files_extra %&gt;% select(location, recording_date_time, length_seconds) %&gt;% slice(2) ## # A tibble: 1 × 3 ## location recording_date_time length_seconds ## &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 228-NE 2022-03-01 00:00:00 600 # Select a 10 minute file and chop it into 60 second segments, creating 10 x 60 second files instead of one 10-minute file wt_chop(input = fe, segment_length = 60, output_folder = &quot;/my/output/folder&quot;) wt_chop will create modulo recordings as needed; this refers to the remaining portion of the recording that is left over after it has been divided into equal intervals of the chosen duration. For example, if a recording is 120 seconds long and segment_length = 50, the modulo recording would be the final 20 seconds since 50 + 50 + 20 = 120. However, if the chosen interval duration is a factor of the total duration of the recording, there will be no modulo recording. For example, if a 120-second recording is divided into 60-second intervals, there will be no modulo recording since 60 is a factor of 120. 2.2.3 Filtering audio files At this stage, you can use the results from the wt_audio_scanner tibble output in order to select the files you’re interested in. Filtering and selecting files generally aligns with the study design or species you’re interested in capturing. Here’s an example of the ABMI’s Stratified Sampling Design for the Ecosystem Health Monitoring program that’s used to pick recordings across a breadth of dates and times in order to maximize the species inventory collected at a location. &gt; abmi_blocks &lt;- as_tibble(data.frame(julian = 90:210) %&gt;% + crossing(time_index = 1:4) %&gt;% + mutate(blocks = case_when(julian %in% 90:139 &amp; time_index == 1 ~ 9, # Midnights during the spring for owls + julian %in% 140:159 &amp; time_index == 1 ~ 10, # Midnights for amphibians, nocturnal breeders + julian %in% 160:179 &amp; time_index == 1 ~ 11, # Midnights for amphibians, nocturnal breeders + julian %in% 180:210 &amp; time_index == 1 ~ 12, # Midnights for amphibians, nocturnal breeders + julian %in% 90:104 &amp; time_index == 3 ~ 1, # Dawn in winter-spring for residents + julian %in% 105:119 &amp; time_index == 4 ~ 2, # Post-dawn in spring for residents, early arrivers + julian %in% 120:139 &amp; time_index == 3 ~ 3, # Dawn for early arrivers + julian %in% 140:149 &amp; time_index == 3 ~ 4, # Dawn for breeding bird chorus + julian %in% 150:159 &amp; time_index == 4 ~ 5, # Post-dawn breeding season + julian %in% 160:169 &amp; time_index == 3 ~ 6, # Dawn for breeding bird chorus + julian %in% 170:179 &amp; time_index == 4 ~ 7, # Post-dawn breeding season + julian %in% 180:210 &amp; time_index == 4 ~ 8, # Post-dawn late breeding season + TRUE ~ NA_real_), + recs = case_when(blocks %in% c(4:7) ~ 180, + TRUE ~ 60))) &gt; &gt; head(abmi_blocks) # A tibble: 6 × 4 julian time_index blocks recs &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; 1 90 1 9 60 2 90 2 NA 60 3 90 3 1 60 4 90 4 NA 60 5 91 1 9 60 6 91 2 NA 60 Now we can apply these blocks to a set of audio files and filter the desired recordings to the stratified design. &gt; files %&gt;% + inner_join(., abmi_blocks, by = c(&quot;julian&quot; = &quot;julian&quot;, &quot;time_index&quot; = &quot;time_index&quot;)) %&gt;% + filter(!is.na(blocks)) %&gt;% # Filter out recordings that don&#39;t fit in a block + group_by(location, blocks) %&gt;% + sample_n(1, replace = F) %&gt;% + select(location, recording_date_time) # A tibble: 12 × 3 # Groups: location, blocks [12] blocks location recording_date_time &lt;dbl&gt; &lt;chr&gt; &lt;dttm&gt; 1 1 228-NE 2022-04-08 07:25:00 2 2 228-NE 2022-04-17 08:33:00 3 3 228-NE 2022-05-15 06:05:00 4 4 228-NE 2022-05-23 05:52:00 5 5 228-NE 2022-06-02 12:00:00 6 6 228-NE 2022-06-10 05:35:00 7 7 228-NE 2022-06-20 07:04:00 8 8 228-NE 2022-07-08 07:16:00 9 9 228-NE 2022-04-05 00:00:00 10 10 228-NE 2022-05-23 00:00:00 11 11 228-NE 2022-06-17 00:00:00 12 12 228-NE 2022-07-08 00:00:00 The Before-After Dose-Response program is another example of a sampling design. Here, we select four recordings near dawn and one recording at dusk for each location between Julian date 140 and 210, for a total of 15 audio minutes. Again, this approach allows users to maximize species diversity while accounting for processing effort. b &lt;- wt_audio_scanner(path = &quot;../2-0-A25&quot;, file_type = &quot;wav&quot;, extra_cols = F) # A list of locations donwload from My Organizations &gt; Manage &gt; Download Locations locs &lt;- read_csv(&quot;../locations.csv&quot;) bz &lt;- b %&gt;% select(file_name:year) %&gt;% inner_join(., locs, by = c(&quot;location&quot;)) %&gt;% # Ensure time zone is correct mutate(recording_date_time = force_tz(recording_date_time, &quot;US/Mountain&quot;)) %&gt;% rowwise() %&gt;% # Get sun angle, 6 degrees before dawn defines civil twilight period mutate(angle = pull(suncalc::getSunlightPosition(date = recording_date_time, lat = latitude, lon = longitude, keep = c(&quot;altitude&quot;))) * (180/pi)) %&gt;% ungroup() %&gt;% filter(between(angle,-6,6), between(julian,140,210)) %&gt;% mutate(hour = hour(recording_date_time)) # Sample one dusk recording bz1 &lt;- bz %&gt;% filter(hour %in% c(20:22)) %&gt;% sample_n(1, replace = F) # And four dawn recordings bz2 &lt;- bz %&gt;% filter(hour %in% c(4:7)) %&gt;% sample_n(4, replace = F) # Bind the dawns and dusks together bzz &lt;- bind_rows(bz1, bz2) &gt; head(bzz) # A tibble: 5 × 17 file_name locat…¹ recording_date_time file_…² julian year latit…³ longi…⁴ eleva…⁵ buffe…⁶ isHid…⁷ trueC…⁸ &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; 1 2-0-A25_20210… 2-0-A25 2021-06-26 21:20:00 wav 177 2021 54.9 -112. NA NA Visible TRUE 2 2-0-A25_20210… 2-0-A25 2021-06-29 05:38:00 wav 180 2021 54.9 -112. NA NA Visible TRUE 3 2-0-A25_20210… 2-0-A25 2021-06-27 05:37:00 wav 178 2021 54.9 -112. NA NA Visible TRUE 4 2-0-A25_20210… 2-0-A25 2021-06-26 05:36:00 wav 177 2021 54.9 -112. NA NA Visible TRUE 5 2-0-A25_20210… 2-0-A25 2021-06-30 05:39:00 wav 181 2021 54.9 -112. NA NA Visible TRUE # … with 5 more variables: comments &lt;chr&gt;, internal_wildtrax_id &lt;dbl&gt;, internal_update_ts &lt;dttm&gt;, angle &lt;dbl&gt;, # hour &lt;int&gt;, and abbreviated variable names ¹ location, ² file_type, ³ latitude, ⁴ longitude, ⁵ elevationMeters, # ⁶ bufferRadiusMeters, ⁷ isHidden, ⁸ trueCoordinates 2.2.4 Geographic filtering Another example of selecting files may be geographic. Keep in mind That you need to manage spatial coordinates along with your locations in order to use these workflows. Here’s an example with selecting recordings with Bird Conservation Regions. library(tidyverse) library(sf) # Clean up the locations locs_next &lt;- locs %&gt;% filter(if_all(c(latitude, longitude), ~ !is.na(.))) %&gt;% select(location, latitude, longitude) %&gt;% distinct() # Create a simple features object. Make it valid and set the CRS. locsset &lt;- st_as_sf(locs_next %&gt;% select(location, latitude, longitude) %&gt;% distinct(), coords = c(&quot;longitude&quot;,&quot;latitude&quot;)) locsset &lt;- st_make_valid(locsset) locsset &lt;- st_set_crs(locsset, 4269) # Load a shapefile of Terrestrial BCRs of North America bcrs &lt;- read_sf(&quot;../BCR_Terrestrial.shp&quot;) # Filter to just Alberta bcrs &lt;- st_make_valid(bcrs) %&gt;% filter(PROVINCE_S == &quot;ALBERTA&quot;) &gt; ggplot(bcrs) + + coord_sf(crs = 4269) + + geom_sf(aes(fill = BCRNAME)) + + theme_bw() + + scale_fill_viridis_d() # Intersect the locations with the BCRs out &lt;- st_intersection(locsset, bcrs) # Join it to the original tibble locss &lt;- out %&gt;% inner_join(., locs, by = c(&quot;location&quot; = &quot;location&quot;)) %&gt;% # Now sample 10 locations per BCR group_by(BCRNAME) %&gt;% sample_n(10, replace = F) %&gt;% select(location, BCRNAME) &gt; locss Simple feature collection with 50 features and 21 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -118.4339 ymin: 49.20788 xmax: -110.1006 ymax: 59.94313 Geodetic CRS: NAD83 # A tibble: 50 × 22 # Groups: BCRNAME [5] location OBJECTID BCR BCRNAME PROVINCE_S COUNTRY REGION WATER Area Perim…¹ Shape…² Shape…³ * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 270-NE 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 2 182-SE 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 3 272-NE 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 4 182-NE 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 5 242-SE 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 6 154-SE 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 7 272-NW 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 8 272-SW 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 9 241-NW 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 10 270-SW 48 8 BOREAL SOFTWOOD SHIELD ALBERTA CANADA CANADA 3 4.63e9 588862. 7.44 0.709 # … with 40 more rows, 10 more variables: geometry &lt;POINT [°]&gt;, latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, # elevationMeters &lt;lgl&gt;, bufferRadiusMeters &lt;dbl&gt;, isHidden &lt;chr&gt;, trueCoordinates &lt;lgl&gt;, comments &lt;chr&gt;, # internal_wildtrax_id &lt;dbl&gt;, internal_update_ts &lt;dttm&gt;, and abbreviated variable names ¹ Perimeter, # ² Shape_Leng, ³ Shape_Area ggplot(bcrs) + coord_sf(crs = 4269) + geom_sf(aes(fill = BCRNAME)) + geom_sf(locss, mapping = aes()) + theme_bw() + theme(legend.position = &quot;none&quot;) + scale_fill_viridis_d() 2.2.5 Collecting files for upload to WildTrax To organize the process of uploading files to WildTrax smoother, it’s recommended to collect all recordings into a single folder, regardless of where they are stored. Whether you’ve saved them on a server, hard drive, or local drive, this approach can help streamline the uploading process and save you time. Depending on the operating system you’re using, there are two common ways to handle your files: linking or copying. Linking involves creating a shortcut to the original file, while copying creates a new, duplicate file. Both options can be beneficial, especially if you have files stored in complex, nested structures. 2.3 Other convenience functions: distance between locations As ARUs are placed on the landscape by different organizations, or over time with different projects, it is possible that spatial locations may overlap. wt_location_distances takes a list of locations downloaded from WildTrax and calculates the distances between all pairs of points. Did you know? You can go to Manage &gt; Download Locations in either a project or an organization to get a list of locations and their attributes. Remember, you need to be an organization administration to perform this operation since organizations manage locations. &gt; # Control locations from the Before-After Dose-Response Landscape Unit #2 &gt; badr2 &lt;- locs %&gt;% + filter(grepl(&#39;^2-0&#39;,location)) &gt; &gt; # Big Grid 9 (Touchoowd) &gt; bu_locs &lt;- bu_locs %&gt;% + filter(grepl(&#39;^BG-9&#39;, location)) &gt; &gt; bu_badr &lt;- bind_rows(badr2, bu_locs) %&gt;% + mutate(Project = case_when(grepl(&#39;^BG-&#39;,location) ~ &quot;Big Grids&quot;,TRUE ~ &quot;Before-After Dose Response&quot;)) &gt; &gt; bu_badr_map &lt;- st_as_sf(bu_badr, coords = c(&quot;longitude&quot;,&quot;latitude&quot;)) &gt; bu_badr_map &lt;- st_make_valid(bu_badr_map) &gt; bu_badr_map &lt;- st_set_crs(bu_badr_map, 4269) ggplot() + coord_sf(crs = 4269) + geom_sf(bu_badr_map, mapping = aes(colour = Project)) + theme_bw() + scale_colour_viridis_d() distances &lt;- wt_location_distances(input_from_tibble = bu_badr) &gt; # Filter points less then 100 meters apart &gt; distances %&gt;% + filter(distance &lt; 100) %&gt;% + arrange(distance) %&gt;% + filter(location_from &lt; distance_to) # A tibble: 13 × 3 location_from distance_to distance &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 2-0-A86 BG-9-95 2.63 2 2-0-A50 BG-9-74 5.46 3 2-0-A12 BG-9-75 8.86 4 2-0-A90 BG-9-85 16.6 5 2-0-A32 BG-9-92 17.8 6 2-0-MA48A 2-0-MA48B 22.5 7 2-0-A87 BG-9-94 34.2 8 2-0-A88 BG-9-93 34.3 9 2-0-MA22A 2-0-MA22B 40.6 10 2-0-A2 BG-9-84 42.8 11 2-0-MA49A 2-0-MA49B 46.2 12 2-0-A30 BG-9-83 74.0 13 2-0-A85 BG-9-97 93.3 2.3.1 Error handling and file standardization wt_audio_scanner will continue to support new file formats and file types. Error handling techniques are being put in place to identify and provide clear messages to users to ensure their data is standard to the WildTrax system before upload. File standardization helps ensure consistency and prevent errors when transferring data across different systems and applications. With these measures, wt_audio_scanner can provide a reliable and versatile tool for working with various audio file formats. Development requests can be submitted as issues to the GitHub repository. 2.4 Using acoustic indices and LDFCs Acoustic indices and long-duration false-colour (LDFC) spectrograms are two tools used in the analysis of acoustic data developed by the Towsey Lab at QUT. Acoustic indices are numerical measurements that quantify various aspects of sound using different measurements that reflect the soundscpe. They are used to identify and track patterns of vocal activity over time, generate soundscape and monitor ecosystem-level patterns and changes. Some commonly known acoustic indices include the Acoustic Complexity Index (ACI), which measures the diversity of sound frequencies and amplitudes, and the Normalized Differenced Soundscape Index (NDSI), which measures the relative different between anthropophonic and biophonic sounds. Long-duration false-color spectrograms are visual representations of acoustic data using index values rather than spectral generation in order to provide detailed views of sound patterns over long periods of time. The use of false-colours allows for easier interpretation of the spectrogram, as different colors can be used to represent different types of sounds. These unique spectrograms are particularly useful in studies of animal vocalizations, as they allow researchers to identify specific vocalizations and track patterns of vocal activity over long periods of time, and determine seasonal phenology patterns. Keep in mind It’s important to familiarize yourself with the AP software before continuing. See here for full installation and support. wildRtrax utilizes the results of the AnalysisPrograms software which generates the csv, json and png files associated to the results, and generates tidy versions of the data that can be joined to the media in order to select recordings based on index values and patterns. Let us demonstrate some different examples while introducing the wt_run_ap and wt_glean_ap functions. wt_run_ap() wt_glean_ap() 2.4.1 Abiotic, geophonic and anthropophonic signal detection Recorder failure, damaged microphones, or recorders that are placed in an environment where prevailing winds muffle the sounds the ARU can hear, such as in alpine environments, can limit the audio quality in order to process data in an effective way. ~12% of the acoustic data collected by the ABMI between 2015 - 2019 (~12TB / 100TB) had a relatively high geophonic index or a malfunction or failure. Due to the large volume of data that is handled, it is no longer efficient to do these processes manually and these steps should be automated as much as possible. The goals are to find efficient ways to screen and filter audio data with high geophony or to flag and omit recordings that will not be used for processing. # Output the results aqd &lt;- wt_glean_ap(x = f2, input_dir = &quot;../data&quot;, purpose = &quot;abiotic&quot;) In contrast, noise pollution is a pervasive problem in modern society, with detrimental effects on human health and well-being, wildlife, and ecosystems. There is growing interest in the use of acoustic indices for noise mapping applications. This approach has several advantages over traditional noise mapping methods. Using acoustic sensors at 310 spatial locations in 2021 across a gradient of human footprint. We recorded sounds for 4-5 days at each location between May and July calculated a range of acoustic indices. We also collected human observations of noise levels (ranked 0-3) and other noise sources (wind, rain, other noise and audio quality) using a standardized survey. We compared the acoustic indices to the human observations to determine the accuracy of the noise map generated from the indices. map_badr &lt;- wt_glean(x = badr, input_dir = &quot;../data&quot;, purpose = &quot;abiotic&quot;) 2.4.2 Biophonic signal detection We can also look at the entire seasonal phenology of an ABMI Ecosystem Health site &gt; boreal_example &lt;- wt_glean_ap(x = boreal_site, input_dir = &quot;../data&quot;) &gt; &gt; boreal_example[[2]] The great part about having a list of the .png files is that you can easily manipulate and generate new LDFCs with other attributes. &gt; boreal_example[[2]] %&gt;% + mutate(hour = lubridate::hour(recording_date_time)) %&gt;% + filter(hour == 0) %&gt;% # Look at only midnight LDFCs and acoustic index values + map_dfr(~lapply(.)) While acoustic indices are good at detecting large scale patterns, it is more difficult to detect rare and elusive signals, especially those that exceed the signal-to-noise threshold to capture the signal. It is important to use this along with spectral validation in WildTrax to determine the source of the environmental noise. 2.5 Linking acoustic data to WildTrax Wildlife Acoustics offers advanced tools for analyzing wildlife vocalizations. Two of their most popular programs are Songscope and Kaleidoscope that allows users to visualize and identify animal songs and calls and also create and run automated classifiers. The output files from these programs can be transformed into WildTrax tags to be uploaded for verification purposes. This is also the primary mechanism that ultrasonic data makes its way into the system if it is being analyzed in Kaleidoscope. 2.5.1 Sonscope results The function wt_songscope_tags reformats the output obtained from a wildlife acoustics songscope recognizer. This transformation involves converting the recognizer tags into tags that do not have a method type. This makes it possible to upload each hit as a tag in a task. &gt; wt_songscope_tags() Keep in mind For certain monitoring programs that deliberately deploy ARUs over extended periods to detect specific species, a high true negative rate is crucial to confirm the absence of the species when required. This typically involves recording for more extended periods of more than 30 minutes. In such cases, it is advisable to use the wt_chop function to segment the media, upload the resulting recordings to WildTrax, generate a task list, and combine it with the results of wt_songscope_tags to import all the data into WildTrax. 2.5.2 Kaleidoscope results Kaleidoscope Pro is a software package that includes a collection of tools designed specifically for bioacoustics analysis work flows. It can be used to automatically identify bat calls and perform cluster analysis (which involves grouping similar calls together), and it also allows the creation and use of classifiers. Once you have used Kaleidoscope to analyze your audio recordings and identify bat calls, you can use the output from Kaleidoscope and transform them into tags using the wt_kaleidoscope_tags function. These tags can then be imported into WildTrax along with the media. wt_kaleidoscope_tags() It’s also recommended to make a list of unique media associated to the tags so WildTrax can merge the audio and tags together. Once you have your formatted tags and audio prepared: Go to a project on WildTrax Click Manage &gt; Upload Recordings to upload the media and generate the tasks Once the recordings are uploaded, click Manage &gt; Upload Tags using the csv output from the wt_kaleidoscope_tags function. Note that wt_kaleidoscope_tags’s data wrangling is “lazy” in that it will attempt the enclose the majority of the signal detected from Kaleidoscope, and assign vocalization types globally. Users are encourage to use Species Verification later in WildTrax in order to make the subsequent batch edits needed to the tags as needed. 2.5.3 Making tasks wt_make_aru_tasks() Tasks don’t always have to be recording or community based. Output from tags from Kaleidoscope or Songscope can also be used to generate tasks. Once your task csvs are created. Go to the desired project and begin the process up uploading them. Keep in mind If you haven’t uploaded recordings to WildTrax yet, you may as well just filter a set of desired files and upload them while generating this task, skipping this step. 2.5.4 Avoiding conflict errors When you upload a recording to WildTrax, it will be permanently stored in the organization in its native length, regardless of whether you generated a task shorter than the recording duration during the initial upload. If you attempt to upload the same recording again, a conflict will arise. To avoid this, it is necessary to first download the list of recordings from the organization, filter out the recordings you plan to upload, and then create a filtering protocol for the remaining recordings. By following this process, you can ensure that there are no conflicts and that all of your recordings are properly organized and managed within WildTrax. "],["3-camera-data-pre-processing.html", "Chapter 3 Camera data pre-processing", " Chapter 3 Camera data pre-processing "],["4-acoustic-data-analysis.html", "Chapter 4 Acoustic data analysis 4.1 Authorizing and downloading data from WildTrax 4.2 Wrangling data for analysis 4.3 Basic analysis 4.4 Advanced analysis", " Chapter 4 Acoustic data analysis Now that we transformed raw sensor data into biological detections using Wildtrax we can use this to inform the metrics we’re wishing to calculate. 4.1 Authorizing and downloading data from WildTrax To access WildTrax data using R, you need to follow a series of initial steps. You should set up your credentials by logging in to WildTrax using Auth0 and storing your username and password as environment variables. Sys.setenv(WT_USERNAME = &quot;guest&quot;, WT_PASSWORD = &quot;Apple123&quot;) Then, you can authenticate your credentials using the wt_auth() function. Once authenticated, you can use various functions to call upon the WildTrax API and download data. For example, the wt_get_download_summary() function provides basic metadata about projects that are available for download. wt_auth() wt_get_download_summary() wt_download_report() 4.2 Wrangling data for analysis 4.2.1 Species identification and observer error Avian population monitoring relies on skilled observers who identify species and estimate population size using visual or acoustic cues. Passive field-based surveys, like “point counts,” use distance and time-interval sampling to calculate meaningful metrics such as population size or density. ARU technology has replaced human-based surveys, establishing them as the new standard for bird population monitoring. False positives (FP) and false negatives (FN) in avian datasets are rarely reported, and standardized reporting, assessing, and determining actions to resolve avian identification errors are crucial. By creating open datasets, researchers can merge them together allowing for larger coproduced [Westwood et al.] and reproducible analyses [REFERENCE]. The integration of traditional human-collected and acoustic data is key to avian monitoring management implications and conservation goals. A standardized system of reporting, assessing and determining actions to resolve avian identification error is crucial to ensure that reporting meets a high data quality standard and that it can be used comfortably in aggregation with other data to answer a wider range of scientific questions. The goals were to provide a standard way of assessing the prevalence of false positives, false negatives and true negatives in avian datasets, to provide solutions to correct and integrate identification error into analyses, and to provide recommendations for the evaluation, training and development of skilled observers. # Omit any abiotic data abiotic_codes &lt;- c(&#39;LIBA&#39;,&#39;MOBA&#39;,&#39;HEBA&#39;,&#39;LITR&#39;,&#39;MOTR&#39;,&#39;HETR&#39;,&#39;LINO&#39;,&#39;MONO&#39;,&#39;HENO&#39;, &#39;LIRA&#39;,&#39;MORA&#39;,&#39;HERA&#39;,&#39;LIWI&#39;,&#39;MOWI&#39;,&#39;HEWI&#39;,&#39;LIAI&#39;,&#39;MOAI&#39;,&#39;HEAI&#39;, &#39;LITN&#39;,&#39;MOTN&#39;,&#39;HETN&#39;,&#39;LIDT&#39;,&#39;MODT&#39;,&#39;HEDT&#39;,&#39;LITF&#39;,&#39;MOTF&#39;,&#39;HETF&#39;) &gt; # Import the species table &gt; head(cls) # A tibble: 6 × 33 species_c…¹ speci…² speci…³ speci…⁴ speci…⁵ speci…⁶ species_date_added speci…⁷ speci…⁸ speci…⁹ speci…˟ speci…˟ &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;lgl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; 1 SHEP Bovidae Ovis aries Domest… Artiod… 2020-10-09 15:05:58 FALSE Mammal… TRUE TRUE TRUE 2 THYVEL Didelp… Thylam… veluti… Dwarf … Didelp… 2022-07-25 00:00:00 FALSE Mammal… TRUE TRUE FALSE 3 FISH Mustel… Martes pennan… Fisher Carniv… 2020-10-09 15:05:58 FALSE Mammal… TRUE TRUE TRUE 4 BOTSTE Ardeid… Botaur… stella… Great … Peleac… 2022-07-28 00:00:00 FALSE Aves TRUE TRUE TRUE 5 CALIRR Didelp… Caluro… irrupta Black-… Didelp… 2022-07-25 00:00:00 FALSE Mammal… TRUE TRUE FALSE 6 LESC Anatid… Aythya affinis Lesser… Anseri… 2021-11-02 11:07:20 FALSE Aves TRUE TRUE TRUE # … with 21 more variables: species_french_name &lt;chr&gt;, species_tsn_id &lt;chr&gt;, # species_allow_multiple_individuals &lt;lgl&gt;, species_id &lt;dbl&gt;, species_french_code &lt;chr&gt;, # species_parent_id &lt;chr&gt;, species_status &lt;chr&gt;, species_has_feeding_buzz &lt;lgl&gt;, species_use_in_aru &lt;lgl&gt;, # species_use_in_cam &lt;lgl&gt;, species_is_domestic &lt;lgl&gt;, species_class_english &lt;chr&gt;, species_aep_code &lt;chr&gt;, # species_order_english &lt;chr&gt;, species_authority &lt;chr&gt;, species_verify_y_pixels_per_khz &lt;dbl&gt;, # species_verify_x_pixels_per_sec &lt;dbl&gt;, species_verify_use_monochrome &lt;lgl&gt;, species_has_night_flight &lt;lgl&gt;, # species_use_abundance_calling_index &lt;lgl&gt;, scientific_name &lt;chr&gt;, and abbreviated variable names … The wildRtrax::wt_ord function conducts a series of steps to return the results of a multi-observer project. The first step in this process involves tidying and preparing the data in a species matrix. The function then runs a redundancy analysis (RDA) on the observer with recording, in other words, location (spatial component) and recording date (temporal component), as a constrained effect. This statistical technique is commonly used to determine the relationship between a set of response variables and a set of predictor variables. In the context of this analysis, the RDA is used to determine the relationship between the observer and the species detections. The wt_ord function also conducts variance partitioning where necessary to determine the contribution of predictor variables in the RDA. This process helps to identify the factors that have the greatest influence on the relationship between the observer and the species detections, such as the geographic region or habitat type determined by the locations used in the analysis. The function also returns results of a PERMANOVA, adjusted R-squared, and F-statistic to provide information on the overall strength and significance of the relationship of the ordination. The PERMANOVA is a non-parametric statistical method used to test the null hypothesis that there is no difference in the means of the groups being compared. The adjusted R-squared and F-statistic provide information on how well the model fits the data, and the significance of the differences observed between the groups. In addition to the RDA, the wt_ord function also runs a generalized linear mixed model (GLMM) on the tag start time against observer, with recording as a random effect. GLMMs are widely used in statistical analysis, and are especially useful for analyzing data that has both fixed and random effects. By using a GLMM in this context, the wt_ord function can determine if there are any significant differences between the observers and the mean of the group. # Using the most recent quality control res &lt;- wt_ord(input = data, min_obs = 11, confidence = 0.67) 4.2.2 False negative rates and BirdNET When processing a task, it is possible for an observer to miss an individual. This false negative (FN) state can be addressed by utilizing BirdNET, a software tool that detects the species in 3-second intervals and intersects it with the tag, resulting in a maximum probability score ranging from 0 to 1. WildTrax, which utilizes the BirdNET API, can extract the maximum probability score exclusively for the species in question from all 3-second intervals that intersect with the tag, returning it as a result. This probability score indicates the likelihood of BirdNET detecting the species in that specific interval, and if BirdNET fails to detect the species, the probability score will be 0. Once all tasks are transcribed, access the Data Downloads page and extract the zip file to obtain the summary report and *_recording_birdnet_summary.csv*. These files will be used to intersect the human-created tags with the results obtained from BirdNET. # Load and prepare the BirdNET data raw_data ## # A tibble: 33,048 × 8 ## organization location recording_date audio_length scientific_name window_start_time window…¹ confi…² ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ABMI 1081-NE 2021-04-06 07:29:00 600 Branta canadensis 51 54 71.7 ## 2 ABMI 1081-NE 2021-04-06 07:29:00 600 Branta canadensis 201 204 45.4 ## 3 ABMI 1081-NE 2021-04-06 07:29:00 600 Branta canadensis 207 210 40.4 ## 4 ABMI 1081-NE 2021-04-06 07:29:00 600 Branta canadensis 210 213 45.6 ## 5 ABMI 1081-NE 2021-04-06 07:29:00 600 Poecile atricapillus 561 564 51.1 ## 6 ABMI 1081-NE 2021-04-06 07:29:00 600 Poecile atricapillus 564 567 44.4 ## 7 ABMI 1081-NE 2021-04-06 07:29:00 600 Poecile atricapillus 567 570 44.2 ## 8 ABMI 1081-NE 2021-04-06 07:29:00 600 Poecile atricapillus 570 573 73.7 ## 9 ABMI 1081-NE 2021-04-06 07:29:00 600 Poecile atricapillus 573 576 51.3 ## 10 ABMI 1081-NE 2021-04-06 07:29:00 600 Poecile atricapillus 576 579 86.1 ## # … with 33,038 more rows, and abbreviated variable names ¹ window_end_time, ² confidence fn &lt;- raw_data %&gt;% filter(!window_start_time &gt;= 180) %&gt;% select(location, recording_date, scientific_name, window_start_time, confidence) %&gt;% distinct() %&gt;% inner_join(., cls %&gt;% select(species_code, species_common_name, scientific_name), by = c(&quot;scientific_name&quot; = &quot;scientific_name&quot;)) %&gt;% add_column(observer = &quot;BirdNET&quot;) %&gt;%s add_column(project_name = &quot;BirdNET Output&quot;) %&gt;% select(project_name, location, recording_date, observer, species_code, window_start_time, confidence) %&gt;% rename(&quot;tag_start_s&quot; = 6) %&gt;% mutate(tag_start_s = as.double(tag_start_s)) %&gt;% add_column(abundance = &quot;1&quot;) fn ## # A tibble: 8,834 × 8 ## project_name location recording_date observer species_code tag_start_s confidence abundance ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 BirdNET Output 1081-NE 2021-04-06 07:29:00 BirdNET CANG 51 71.7 1 ## 2 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 0 94 1 ## 3 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 3 92.1 1 ## 4 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 6 77.3 1 ## 5 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 9 92.5 1 ## 6 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 12 92.3 1 ## 7 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 15 94.2 1 ## 8 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 18 91.4 1 ## 9 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 21 89.4 1 ## 10 BirdNET Output 1081-NE 2021-05-14 06:06:00 BirdNET LEFL 24 92.7 1 ## # … with 8,824 more rows 4.2.3 Abundance estimation Estimating abundance is crucial for understanding population dynamics and making informed conservation decisions. By accurately quantifying the number of individuals within a survey area, researchers can track population changes over time and evaluate the effectiveness of conservation or management efforts. This is typically done through repeated surveys over time, which allow for the calculation of important population metrics such as occupancy, detectability, and colonization/extinction. However, sometimes estimating abundance is not always possible, particularly when dealing with large or elusive species. In these cases, the WildTrax platform uses “Too Many to Tag” (TMTT) as a way to indicate that the number of individuals cannot be directly counted or estimated. To address this issue, wildRtrax provides the wt_replace_tmtt function, which runs a generalized linear mixed model using existing data in the dataset to generate a numeric value for TMTT. For instance, if a survey records 100 detections, of which 70 are abundance = 1, 29 are abundance = 2, and 1 is abundance = TMTT, the function would estimate the TMTT value at approximately 1.2. This helps improve the accuracy of abundance estimates and allows for more robust analysis. wt_replace_tmtt() 4.3 Basic analysis Wildtrax provides the basis for a variety of different biological metrics and data, which can be analyzed using basic statistical techniques to gain insights into wildlife populations and their distribution. 4.3.1 Species presence raw_basic_data &lt;- dir_ls(path = &quot;/users/alexandremacphail/desktop/fn&quot;, regexp = &quot;*basic_summary.csv&quot;) %&gt;% map_df(~read_csv(., col_types = cols(recording_date = col_character()))) data_logistic_wtsp &lt;- raw_basic_data %&gt;% filter(!species_code %in% abiotic_codes, !grepl(&#39;^U&#39;,species_code)) %&gt;% mutate(present = case_when(species_code == &quot;WTSP&quot; ~ 1, TRUE ~ 0)) %&gt;% select(location, latitude, longitude, recording_date, species_code, present) %&gt;% distinct() %&gt;% mutate(hour = hour(recording_date)) %&gt;% pivot_wider(names_from = species_code, values_from = present, values_fill = 0) # create a logistic regression model mylogit &lt;- glm(species_presence ~ location + recording_date_time + forest_type, data = data_logistic_wtsp, family = binomial) # summary of the model summary(mylogit) 4.3.2 Species accumulation and rarefaction Species accumulation refers to the process of counting the number of different species present in a sample of a particular size. The idea is to keep adding new samples until the total number of species observed reaches a plateau or levels off. The curve that results from plotting the number of species against the number of samples is called a species accumulation curve, and it provides information about the rate of species discovery and the completeness of sampling. Rarefaction is a statistical method used to estimate the expected number of species in a community, given a fixed number of individuals or samples. This technique is particularly useful when comparing the diversity of different communities that have been sampled unevenly, i.e., with different sample sizes. The rarefaction curve represents the expected number of species in a community as a function of the number of individuals or samples, and it can help researchers make fair comparisons of diversity between communities. 4.4 Advanced analysis 4.4.1 Occupancy modelling wt_occupancy() 4.4.2 Constructing a classifier wt_download_tag_report() "],["5-camera-data-analysis.html", "Chapter 5 Camera data analysis", " Chapter 5 Camera data analysis "],["6-conclusions.html", "Chapter 6 Conclusions", " Chapter 6 Conclusions "]]
