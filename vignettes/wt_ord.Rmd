---
title: "What influences identification error in avian count data?"
author: "Alexander G. MacPhail"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

# Introduction

Avian point-count surveys rely on skilled observers to identify species and estimate numbers of individuals using distinct visual or acoustic signals. Since birds rely on acoustic cues to attract mates, defend territory and communicate with one another, humans can take advantage of these unique signatures in order to identify species and individuals. In passive field-based surveys (i.e. "point counts"), human observers use distance and time-interval sampling in order for analysts to incorporate perceptibility and dectectability offsets (Solymos et al. 2013) to accurately calculate meaningful biological metrics such as density or occupancy. These are then are used to make conservation decisions for the species. The accuracy and reliability of the results of this sampling must be high otherwise incorrect conclusions and flawed decision-making can lead to the improper management of a species or landscape.

Since the advent of affordable autonomous recording unit (ARU) technology, single-visit human-based surveys have been rapidly replaced by archivable acoustic recordings of the environment. This has established both the fields of bioacoustics and ecoacoustics, launching ARUs as the new standard for bird population monitoring. The comparison of human-based surveys and acoustic recording technology for monitoring avian populations is well-documented (Shonfield et al. 2017, Van Wilgenburg et al. 2017, Venier et al. 2017, Pankratz et al. 2017, Yip et al. 2019). Factors such as distance from the observer or ARU (Yip et al. 2016, Knight et al. 2020, Van Wilgenburg et al. 2017), frequency range and habitat type (Yip et al. 2016) all play an important role in whether a species is detected (true positive; *TP*) or not (true negative; *TN*). Researchers can leverage the ability to archive acoustic recording data over point counts in order to improve data processing quality and benefit from long-term secure data storage. Ensuring the proper integration of traditional human-collected and acoustic data [REFERENCE] is key to avian monitoring management implications and conservation goals. By creating open data sets, (Docherty et al. 2021) researchers can also merge data sets together allowing for larger coproduced (Westwood et al. 2020) and reproducible analyses.

False positives (*FP*) and false negatives (*FN*) in avian data sets are rarely reported in the scientific literature suggesting that they are either flawlessly collected or species are identified to a high degree of accuracy and / or precision. *FP*s can increase the count and therefore skew the population estimates for certain species. Morrison (2016) proposes that to avoid observer error in plant identification, additional training including active feedback approaches, continual evaluation and calibration among a multi-observer set are important. Similarly, Dennett and Nielsen (2019) determined that abundance and scale of the survey were the most influential factors in detecting rare species of plants. These types of assessments would be operationally difficult or costly to implement for field-based avian surveys given the mobile nature of birds, however utilizing the ability to return to acoustic recording would show the potential to determine the error in the avian count data. Standardizing multiple observers is known to be effective for correcting inter-observer variability in species detections in a monitoring program [REFERENCE]. While acoustic data excludes any visual cues for species identification, the principal advantage of collecting avian data with ARUs is that a permanent copy of the recording can be kept for future reference.

A standardized system of reporting, assessing and determining actions to resolve avian identification error is crucial to ensure that reporting meets a high data quality standard and that it can be used comfortably in aggregation with other data to answer a wider range of scientific questions. The goals were to provide a standard way of assessing the prevalence of false positives, false negatives and true negatives in avian datasets, to provide solutions to correct and integrate identification error into analyses, and to provide recommendations for the evaluation, training and development of skilled observers. 

# Methods

```{r, eval = T, include = T, warning = F, message = F}
library(tidyverse)
library(lubridate)
library(fitdistrplus)
library(furrr)
library(purrr)
library(scales)
library(doParallel)
library(tools)
library(wildRtrax)
library(gamlss)
library(gamlss.dist)
library(vegan)
library(pipeR)
library(gamlss.add)
library(plotly)
library(fs)
library(lme4)
library(lmerTest)
library(vctrs)
library(extraDistr)

knitr::opts_chunk$set(collapse = TRUE, comment = '#>')

```

Data processing took place in a web-enabled, environmental sensor data platform called [WildTrax](https://www.wildtrax.ca). WildTrax allows users to store, manage, process, verify, share and discover data deriving from environmental sensors, such as ARUs, remote camera traps. 

[FIGURE]

1. Assessing differences in avian communities between observers

A total of 12 observers were given the same ten, 3-minute long recordings (n<sub>rep</sub>=120, n<sub>min_total</sub>=360) and instructed to process data to identify time-of-first-detection of each species-individual on the recording. Species detections in WildTrax are designated as **tags** where a user draws a box around the spectral signature in the spectrogram, with confirmation via the audio, and WildTrax stores the tag metadata, e.g. frequency range = Hz, duration = ms.

[FIGURE]

Each observer were given the same recordings to process independent of one another in groupings of data called [projects](). A user is given access to a project through user authentication and membership so that data processing could be done blind. Locations were placed on a map but within a 5.5 km buffer so the user also did not know exactly what habitat type they were processing data in. Projects were then merged together to create the full dataset for this protocol.

[FIGURE]

Data was downloaded from WildTrax projects using `wt_download_report` function. This is an API that allows users authorized to the projects or organization on WildTrax to download the report data directly to R.

```{r, eval = F, include = T}

# DOWNLOAD LIKE THIS WHEN THIS IS WORKING FOR GOOGLE AUTH0

# wt_auth(force = T, "google")
#
# wt_get_download_summary()
#
# wt_download_report()

```

Then, using the `wildRtrax::wt_ord` function the data will be run through a series of steps to do the following:

- [*Tidies*](https://www.tidyverse.org/) and prepares data in a species matrix
- Runs the redundancy analysis (RDA) on observer with recording as a constrained effect to determine the relationship between observer and species detections
- Runs a generalized linear mixed model (GLMM) on tag start time against observer with recording as a random effect
- Creates an ordination plot of the RDA and raw data summary for the time of first detection faceted by each observer
- Returns results of a PERMANOVA, Adjusted *R*<sup>2<sup> and *F*-statistic corresponding to the overall strength and significance of the relationship of the ordination
- Returns stepwise model output of the GLMM to determine significant differences between observers and the mean of the group

Import the species table and raw data that will be used for analysis. This comes from a single WildTrax project that was merged together. 

```{r, eval = T, include = T, warning = F, message = F}
# Omit any abiotic data
abiotic_codes<-c('LIBA','MOBA','HEBA','LITR','MOTR','HETR','LINO','MONO','HENO',
                 'LIRA','MORA','HERA','LIWI','MOWI','HEWI','LIAI','MOAI','HEAI',
                 'LITN','MOTN','HETN','LIDT','MODT','HEDT','LITF','MOTF','HETF')

# Import the species table
cls <- read_csv("/users/alexandremacphail/desktop/commonluspp.csv") %>%
  mutate(scientific_name = paste0(species_genus, " ", species_name))

# Setup the data from the report -- change this once wt_auth() is working
data <-
  dir_ls(path = "/users/alexandremacphail/desktop/qc", regexp = "*tag_details_report.csv") %>%
  map(~read_csv(., col_types = list(location = col_character(), abundance = col_character(), verified_by = col_character()))) %>%
  bind_rows()

# Load and prepare the BirdNET data

fn <- dir_ls(path = "/users/alexandremacphail/desktop/qc", regexp = "*recording_birdnet.csv") %>%
  map(~read_csv(., col_types = list(location = col_character()))) %>%
  bind_rows()

nfn <- fn %>%
  filter(!window_start_time >= 180) %>%
  select(location, recording_date, scientific_name, window_start_time, confidence) %>%
  distinct() %>%
  inner_join(., cls %>% select(species_code, species_common_name, scientific_name), by = c("scientific_name" = "scientific_name")) %>%
  add_column(observer = "BirdNET") %>%
  add_column(project_name = "BirdNET Output") %>%
  select(project_name, location, recording_date, observer, species_code, window_start_time, confidence) %>%
  rename("tag_start_s" = 6) %>%
  mutate(tag_start_s = as.double(tag_start_s)) %>%
  add_column(abundance = "1")

data_bn <- bind_rows(data, nfn)

```

This is the underlying Roxygen parameters that supports the `wt_ord` function in WildTrax.

```{r}

#' @section `wt_ord` details:
#'
#' @description 

#' @param input Character; A wt_download_report tibble
#' @param min_obs Numeric; The minimum number of replicates you want to use
#' @param confidence Numeric; The confidence of the ellipses in the RDA
#' 
#' @import 
#' @importFrom 
#' @importFrom 
#' @export
#'
#' @examples
#' \dontrun{
#' res <- wt_prd(input = data, min_obs = 10, confidence = 0.67)
#' }
#'
#' @return A list containing the following:

```

And the `wt_ord` function itself.

```{r}

# Create the wt_ord function
wt_ord <- function(input = x, min_obs, confidence) {
  
  # Filter by the minimum amount of observers. Less takes longer to run
  multi <- input %>%
    group_by(location, recording_date) %>%
    mutate(unique_times = n_distinct(observer)) %>%
    ungroup() %>%
    filter(unique_times >= min_obs) %>%
    select(-unique_times)
  
  # Set up the data
  multi <- multi %>%
    mutate(abundance = case_when(abundance == "TMTT" ~ "4", abundance == "CI 1" ~ "1", abundance == "CI 2" ~ "2", abundance == "CI 3" ~ "3", TRUE ~ abundance),
           abundance = as.numeric(abundance)) %>%
    group_by(project_name, location, recording_date, species_code, observer) %>%
    mutate(indvs = max(individual_appearance_order)) %>%
    ungroup() %>%
    dplyr::select(project_name, location, recording_date, species_code, observer, indvs, abundance) %>%
    distinct() %>%
    group_by(project_name, location, recording_date, species_code, observer) %>%
    summarise(abundance = case_when(max(abundance) > max(indvs) ~ max(abundance), TRUE ~ max(indvs))) %>%
    ungroup()
  
  # Create the species matrix 
  multi2 <- multi %>%
    dplyr::select(project_name, location, recording_date, observer, species_code, abundance) %>%
    distinct() %>%
    group_by(project_name, location, recording_date, observer, species_code) %>%
    mutate(abundance = as.numeric(max(abundance))) %>%
    ungroup() %>%
    arrange(location, observer, species_code) %>%
    group_by(species_code, project_name, location, recording_date, observer) %>%
    distinct() %>%
    ungroup() %>%
    filter(!species_code %in% abiotic_codes) %>%
    arrange(species_code, project_name, location, recording_date, observer) %>%
    pivot_wider(names_from = species_code, values_from = abundance, values_fill = 0) %>%
    mutate_if(is.integer, as.numeric) %>%
    replace(is.na(.), 0) %>%
    rowwise() %>%
    mutate(total = sum(c_across(`ALFL`:`YRWA`))) %>%
    ungroup() %>%
    filter(!total < 1) %>%
    select(-total)
  
  # Create the groups 
  multi_type <- multi2 %>%
    dplyr::select(location, recording_date, observer) %>%
    distinct()
  
  # Run the RDA 
  t3 <- rda(multi2[,-c(1:4)] ~ observer + location + recording_date, data = multi_type)
  
  # Print the results of a permutation test for the constrained ordination
  ordistep(t3)
  
  # Set up the output - scores first
  t3scores <- scores(t3, display = "sites") %>%
    as.data.frame() %>%
    rownames_to_column("site") %>%
    bind_cols(., multi_type)
  
  # Then eigenvectors 
  t3vect <- scores(t3, display = "species") %>%
    as.data.frame()
  
  # Now plot everything for the ordination
  plot_RDA <- ggplot(data = t3scores, aes(x = RDA1, y = RDA2)) +
    geom_point(data = t3scores, aes(x = RDA1, y = RDA2, colour = observer), alpha = 0.6) +
    stat_ellipse(data = t3scores, aes(colour = observer), linetype = 4, type = 'norm', level = confidence) +
    geom_vline(xintercept = c(0), color = "#A19E99", linetype = 2) +
    geom_hline(yintercept = c(0), color = "#A19E99", linetype = 2) +
    geom_segment(data = t3vect, aes(x = 0, y = 0, xend = RDA1, yend = RDA2), arrow = arrow(length = unit(0.2, "cm"))) +
    geom_text(data = t3vect, aes(x = RDA1, y = RDA2, label = rownames(t3vect))) +
    # Apply ABMI themes
    labs(x = paste0("RDA1 ", round(t3$CA$eig[[1]],2), '%'),
         y = paste0("RDA2 ", round(t3$CA$eig[[2]],2), '%'),
         title = paste0("RDA of observer detections constrained by recording"))
  
  # Time to first detection data setup
  dd <- input %>%
  select(location, recording_date, 
         observer, species_code, individual_appearance_order, 
         tag_start_s, tag_duration_s,  min_tag_freq, max_tag_freq, vocalization, abundance) %>%
  distinct() %>%
  group_by(location, recording_date) %>%
  mutate(unique_times = n_distinct(observer)) %>%
  ungroup() %>%
  filter(unique_times >= min_obs) %>%
  select(-unique_times) %>%
  relocate(abundance, .after=individual_appearance_order) %>%
  mutate_at(vars(min_tag_freq, max_tag_freq), ~as.numeric(str_replace(.,"kHz",""))) %>%
  group_by(location, recording_date, observer) %>%
  mutate(detection_order = row_number()) %>%
  ungroup() %>%
  mutate(freq_diff = max_tag_freq - min_tag_freq) %>%
  mutate(Unknown = case_when(grepl('^U',species_code) ~ "Unknown", TRUE ~ "Species"))
  
  # Plot the results
d <- ggplot(dd, aes(x=tag_start_s,y=detection_order,colour=Unknown,shape=Unknown)) +
  geom_point(alpha = 0.2) +
  geom_smooth(alpha = 0.6) +
  ylim(0,50) +
  facet_wrap(~observer, scales="free_x") +
  ggtitle("Time to first detection of species and unknown tags") +
  xlab("Tag start time (seconds)") + ylab("Detections per recording")

#Return all objects 
  return(list(plot_RDA, # Ordination
              d, # Time to first detection plot 
              t3, # Ordination 
              t3scores %>% as_tibble(), # Ordination scores
              vegan::anova.cca(t3, permu = 999), # Permutation Test for RDA (ANOVA-like)
              vegan::adonis(multi2[,-c(1:4)] ~ observer + location + recording_date, data = multi_type, distance = "bray"))) # PERMANOVA
}

```

Now we run the function.

```{r, eval = T, include = T, warning = F, message = F}
# Using the most recent quality control
res <- wt_ord(input = data, min_obs = 11, confidence = 0.67)

```

# Results

## Multivariate analysis of species detections


```{r, eval = T, include = T}

res[[1]] # Ordination

```

## Time to first detection between observers

```{r, warning = F, message = F}

res[[2]] # Time to first detection

```

## False negative rates and use of BirdNET

```{r}


```


# Discussion

## Steps to identify species identification errors

- Reproduce multiobs data
- Run `wt_ord` and identify obs

## Training, skill development and testing

- Training well
- Develop skills using results of multi-obs stuff
- Add to species verification half are 1/2 verified to learn
- Exam to make sure productivity, accuracy and precision is high

# References








This is just other stuff I tried.

```{r, eval = F, include = F}

dd <- input %>%
  select(location, recording_date, 
         observer, species_code, individual_appearance_order, 
         tag_start_s, tag_duration_s,  min_tag_freq, max_tag_freq, vocalization, abundance) %>%
  distinct() %>%
  group_by(location, recording_date) %>%
  mutate(unique_times = n_distinct(observer)) %>%
  ungroup() %>%
  filter(unique_times >= 11) %>%
  select(-unique_times) %>%
  relocate(abundance, .after=individual_appearance_order) %>%
  mutate_at(vars(min_tag_freq, max_tag_freq), ~as.numeric(str_replace(.,"kHz",""))) %>%
  group_by(location, recording_date, observer) %>%
  mutate(detection_order = row_number()) %>%
  ungroup() %>%
  mutate(freq_diff = max_tag_freq - min_tag_freq) %>%
  mutate(Unknown = case_when(grepl('^U',species_code) ~ "Unknown", TRUE ~ "Species"))
  
d <- ggplot(dd, aes(x=tag_start_s,y=detection_order,colour=Unknown,shape=Unknown)) +
  geom_point(alpha = 0.2) +
  geom_smooth(alpha = 0.6) +
  ylim(0,50) +
  facet_wrap(~observer, scales="free_x") +
  abmi.themes::theme_abmi() +
  abmi.themes::scale_color_abmi() +
  ggtitle("Time to first detection of species and unknown tags") +
  xlab("Tag start time (seconds)") + ylab("Detections per recording")


j2 <- wt_ord(input = data, min_obs = 11, confidence = 0.67)

p1 <- lmer(tag_start_s ~ observer + (1|location) + (1|recording_date), data = dd)
library(lattice)

randoms <- ranef(p1)
dotplot(randoms)
qqmath(randoms)

p2 <- lmer(tag_start_s ~ 1 + (1|observer), data = dd)

p3 <- lmer(tag_start_s ~ observer + (1|location) + (1|recording_date) + (1|species_code) + (1|abundance), data = dd)

anova(p1,p3)

confint(p3)

summary(p1)
plot(p1)

p4 <- gamlss(log(tag_start_s) ~ observer + location + recording_date, data=dd)
plot(p4)

anova(p1, p4)


```


```{r, eval = F, include = F}
###Take the eigenvalues for each point and determine the sum of squares to get a preliminary score
rich_score <- j2[[4]] %>%
  group_by(observer) %>%
  summarise(score = sum(RDA1^2 + RDA2^2)) %>%
  arrange(-score) %>%
  ungroup()

#Figure out the distribution of the data
descdist(rich_score$score, discrete = F, boot = 500)

h <- ggplot(rich_score, aes(x=reorder(observer,-score), y=score)) + geom_point() + geom_smooth()

h
#Fit data to weibull distribution
fit <- fitdist(rich_score$score, "pois", "mme")

mod <- lmer(tag_start_s ~ observer + (1|location) + (1|recording_date), data = dd)

p1 <- lmer(tag_start_s ~ observer + (1|location) + (1|recording_date), data=dd)
nb1 <- glmer.nb(tag_start_s ~ observer + (1|location) + (1|recording_date), data=dd)
summary(p1)
plot(p1)

```


```{r, eval = F, include = F}
ggplot(dd, aes(x=reorder(observer,-freq_diff),y=freq_diff,fill=observer)) +
  geom_boxplot() +
  abmi.themes::theme_abmi() +
  abmi.themes::scale_fill_abmi() +
  theme(axis.text.x = element_text(angle = 85, vjust = 0.5, hjust=0.5)) +
  ggtitle("Average frequency range of detections") +
  theme(axis.text.x = element_blank()) +
  xlab("Observer within group") + ylab("Average frequency range of tags")

un <- dd %>%
  group_by(observer, Unknown) %>%
  tally() %>%
  ungroup() %>%
  pivot_wider(names_from = Unknown, values_from = n) %>%
  mutate(prop = paste0(round(((Unknown / Species)*100),2)," %")) %>%
  pivot_longer(cols = Species:Unknown, names_to = "Unknown")

ggplot(un, aes(fill=Unknown, y=value, x=reorder(observer,-value))) +
  geom_bar(position="dodge", stat="identity") + coord_flip() +
  abmi.themes::theme_abmi() +
  abmi.themes::scale_fill_abmi() +
  geom_text(aes(label = ifelse(Unknown == "Unknown",prop,""), hjust=-0.7, vjust =-0.8)) +
  #gghighlight::gghighlight(observer == "Gill Holmes", label_key = observer) +
  ylab("Count of tags") + xlab("Observer") + ggtitle("Proportion of unknowns tagged per observer")


uns <- dd %>%
  mutate(Unknown = case_when(grepl('^U',species_code) ~ "Unknown", TRUE ~ "Species")) %>%
  select(observer, Unknown, tag_start_s) %>%
  distinct()

ggplot(uns, aes(x=observer,y=tag_start_s,fill=Unknown)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 85, vjust = 0.5, hjust=0.5)) +
  abmi.themes::theme_abmi() +
  abmi.themes::scale_fill_abmi() +
  ylab("Tag start time (seconds)") + xlab("Observer") +
  facet_wrap(~Unknown)

```

