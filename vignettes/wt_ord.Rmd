---
title: "What influences identification error in avian count data?"
author: "Alexander G. MacPhail"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

# Introduction

Avian count surveys rely on skilled observers to identify species and estimate numbers of individuals using distinct visual or acoustic signals. Since birds rely on acoustic cues to attract mates, defend territory and communicate with one another, humans can take advantage of these unique signatures in order to identify species and individuals. In passive field-based surveys (i.e. "point counts"), human observers use distance and time-interval sampling in order for analysts to incorporate perceptibility and dectectability offsets (Buckland et al. 2001, Farnsworth et al. 2002, Solymos et al. 2013) to accurately calculate meaningful biological metrics such as population size or density which are then are used to make conservation decisions. The accuracy and reliability of these results must be high otherwise incorrect conclusions and flawed decision-making can lead to the improper management of a species or landscape.

Since the advent of affordable autonomous recording unit (ARU) technology, single-visit human-based surveys have been rapidly replaced by archiveable acoustic recordings of the environment. This has established both the fields of bioacoustics and ecoacoustics, launching ARUs as the new standard for bird population monitoring. The comparison of human-based surveys and acoustic recording technology for monitoring avian populations is well-documented (Shonfield et al. 2017, Van Wilgenburg et al. 2017, Venier et al. 2017, Pankratz et al. 2017, Yip et al. 2019). Factors such as distance from the observer or ARU (Yip et al. 2016, Knight et al. 2020, Van Wilgenburg et al. 2017), frequency range and habitat type (Yip et al. 2016) all play an important role in whether a species is detected (true positive; *TP*) or not (true negative; *TN*). Researchers can leverage the acoustic recording data over point counts in order to improve data processing quality and benefit from long-term secure data storage. Ensuring the proper integration of traditional human-collected and acoustic data [REFERENCE] is key to avian monitoring management implications and conservation goals. By creating open data sets, (Docherty et al. 2021) researchers can also merge data sets together allowing for larger coproduced (Westwood et al. 2020) and reproducible analyses.

False positives (*FP*) and false negatives (*FN*) in avian data sets are rarely reported in the scientific literature suggesting that they are either flawlessly collected or species are identified to a high degree of accuracy and / or precision. *FP*s can increase the count and therefore skew the population estimates for certain species. Morrison (2016) proposes that to avoid observer error in plant identification, additional training including active feedback approaches, continual evaluation and calibration among a multi-observer set are important. Similarly, Dennett and Nielsen (2019) determined that abundance and scale of the survey were the most influential factors in detecting rare species of plants. These types of assessments would be operationally difficult or costly to implement for field-based avian surveys given the mobile nature of birds, however utilizing the ability to return to acoustic recording would show the potential to determine the error in the avian count data. Standardizing multiple observers is known to be effective for correcting inter-observer variability in species detections in a monitoring program [REFERENCE]. While acoustic data excludes any visual cues for species identification, the principal advantage of collecting avian data with ARUs is that a permanent copy of the recording can be kept for future reference.

A standardized system of reporting, assessing and determining actions to resolve avian identification error is crucial to ensure that reporting meets a high data quality standard and that it can be used comfortably in aggregation with other data to answer a wider range of scientific questions. The goals were to provide a standard way of assessing the prevalence of false positives, false negatives and true negatives in avian datasets, to provide solutions to correct and integrate identification error into analyses, and to provide recommendations for the evaluation, training and development of skilled observers. 

# Methods

```{r, eval = T, include = T, warning = F, message = F}
library(tidyverse)
library(lubridate)
library(fitdistrplus)
library(furrr)
library(purrr)
library(scales)
library(doParallel)
library(tools)
library(wildRtrax)
library(gamlss)
library(gamlss.dist)
library(vegan)
library(pipeR)
library(gamlss.add)
library(plotly)
library(fs)
library(lme4)
library(lmerTest)
library(vctrs)
library(extraDistr)

knitr::opts_chunk$set(collapse = TRUE, comment = '#>')

```

## Divergence and similarities in avian counts between observers

[FIGURE]

A total of 11 observers were given the same ten, 3-minute long recordings (n<sub>rep</sub>=120, n<sub>min_total</sub>=360) and instructed to process data to identify time-of-first-detection of each species-individual on the recording. Species detections in WildTrax are designated as **tags** where a user draws a box around the spectral signature in the spectrogram, with confirmation via the audio. WildTrax stores the tag metadata, e.g. frequency range = Hz, duration = ms. Each observer were given the same recordings to process independent of one another in groupings of data called [projects](). A user is given access to a project through user authentication and membership so that data processing could be done blind. Locations were placed on a map but within a 5.5 km buffer so the user also did not know exactly what habitat type or exact spatial location they were processing data in as not to bias species detections based on community structure. Projects were then merged together to create the full dataset for this protocol.

[FIGURE]




```{r, eval = T, include = T, warning = F, message = F}

# DOWNLOAD LIKE THIS WHEN THIS IS WORKING FOR GOOGLE AUTH0

# wt_auth(force = T, "google")
#
# wt_get_download_summary()
#
# wt_download_report()

# Omit any abiotic data
abiotic_codes<-c('LIBA','MOBA','HEBA','LITR','MOTR','HETR','LINO','MONO','HENO',
                 'LIRA','MORA','HERA','LIWI','MOWI','HEWI','LIAI','MOAI','HEAI',
                 'LITN','MOTN','HETN','LIDT','MODT','HEDT','LITF','MOTF','HETF')

# Import the species table
cls <- read_csv("/users/alexandremacphail/desktop/commonluspp.csv") %>%
  mutate(scientific_name = paste0(species_genus, " ", species_name))

# Setup the data from the report -- change this once wt_auth() is working
data <-
  dir_ls(path = "/users/alexandremacphail/desktop/qc", regexp = "*tag_details_report.csv") %>%
  map(~read_csv(., col_types = list(location = col_character(), abundance = col_character(), verified_by = col_character()))) %>%
  bind_rows()

head(data)

```

Data was downloaded from WildTrax projects using `wt_download_report` function in the `wildRtrax` package. This is an API that allows users authorized to the projects or organization on WildTrax to download the report data directly to R. Here we are also importing the WildTrax species table and raw data that will be used for analysis. We'll also create a list of abiotic variables that we'll omit later. 

The `wildRtrax::wt_ord` function conducts a series of steps to return the results of a multi-observer project. The first step in this process involves tidying and preparing the data in a species matrix. The `tidyverse` familyl of packages is utilized for this process, which is a collection of packages designed for efficient data manipulation and analysis. The `wt_ord` function then runs a redundancy analysis (RDA) on the observer with recording, in other words, location (spatial component) and recording date (temporal component), as a constrained effect. This statistical technique is commonly used to determine the relationship between a set of response variables and a set of predictor variables. In the context of this analysis, the RDA is used to determine the relationship between the observer and the species detections. The `wt_ord` function also conducts variance partitioning where necessary to determine the contribution of predictor variables in the RDA. This process helps to identify the factors that have the greatest influence on the relationship between the observer and the species detections. The function also returns results of a *PERMANOVA*, adjusted *R*-squared, and *F*-statistic to provide information on the overall strength and significance of the relationship of the ordination. The *PERMANOVA* is a non-parametric statistical method used to test the null hypothesis that there is no difference in the means of the groups being compared. The adjusted *R*-squared and *F*-statistic provide information on how well the model fits the data, and the significance of the differences observed between the groups.

In addition to the RDA, the wt_ord function also runs a generalized linear mixed model (GLMM) on the tag start time against observer, with recording as a random effect. GLMMs are widely used in statistical analysis, and are especially useful for analyzing data that has both fixed and random effects. By using a GLMM in this context, the wt_ord function can determine if there are any significant differences between the observers and the mean of the group.

This is the underlying Roxygen parameters that supports the `wt_ord` function in WildTrax.

```{r, eval=F, include=F,message=F,warning=F}

#' @section `wt_ord` details:
#'
#' @description 

#' @param input Character; A wt_download_report tibble
#' @param min_obs Numeric; The minimum number of replicates you want to use. wt_ord will omit 
#' @param confidence Numeric; The confidence of the ellipses in the RDA
#' 
#' @import 
#' @importFrom 
#' @importFrom 
#' @export
#'
#' @examples
#' \dontrun{
#' res <- wt_prd(input = data, min_obs = 10, confidence = 0.67)
#' }
#'
#' @return A list containing the following:

```

And the `wt_ord` function itself.

```{r, eval=T, include=T, message=F, warning=F}

# Create the wt_ord function
wt_ord <- function(input = x, min_obs, confidence) {
  
  # Filter by the minimum amount of observers. Less takes longer to run
  multi <- input %>%
    group_by(location, recording_date) %>%
    mutate(unique_times = n_distinct(observer)) %>%
    ungroup() %>%
    filter(unique_times >= min_obs) %>%
    select(-unique_times)
  
  # Set up the data
  multi <- multi %>%
    mutate(abundance = case_when(abundance == "TMTT" ~ "4", abundance == "CI 1" ~ "1", abundance == "CI 2" ~ "2", abundance == "CI 3" ~ "3", TRUE ~ abundance),
           abundance = as.numeric(abundance)) %>%
    group_by(project_name, location, recording_date, species_code, observer) %>%
    mutate(indvs = max(individual_appearance_order)) %>%
    ungroup() %>%
    dplyr::select(project_name, location, recording_date, species_code, observer, indvs, abundance) %>%
    distinct() %>%
    group_by(project_name, location, recording_date, species_code, observer) %>%
    summarise(abundance = case_when(max(abundance) > max(indvs) ~ max(abundance), TRUE ~ max(indvs))) %>%
    ungroup()
  
  # Create the species matrix 
  multi2 <- multi %>%
    dplyr::select(project_name, location, recording_date, observer, species_code, abundance) %>%
    distinct() %>%
    group_by(project_name, location, recording_date, observer, species_code) %>%
    mutate(abundance = as.numeric(max(abundance))) %>%
    ungroup() %>%
    arrange(location, observer, species_code) %>%
    group_by(species_code, project_name, location, recording_date, observer) %>%
    distinct() %>%
    ungroup() %>%
    filter(!species_code %in% abiotic_codes) %>%
    arrange(species_code, project_name, location, recording_date, observer) %>%
    pivot_wider(names_from = species_code, values_from = abundance, values_fill = 0) %>%
    mutate_if(is.integer, as.numeric) %>%
    replace(is.na(.), 0) %>%
    rowwise() %>%
    mutate(total = sum(c_across(`ALFL`:`YRWA`))) %>%
    ungroup() %>%
    filter(!total < 1) %>%
    select(-total)
  
  # Create the groups 
  multi_type <- multi2 %>%
    dplyr::select(location, recording_date, observer) %>%
    distinct()
  
  if (length(unique(multi2$location)) == 1) {
    stop(print("You need at least two recordings duplicated in order to generate the analysis"))
  }
  
  # Run the RDA 
  ordination <- rda(multi2[,-c(1:4)] ~ observer + location + recording_date, data = multi_type)
  ordination_obs <- rda(multi2[,-c(1:4)] ~ observer, data = multi_type)
  ordination_loc <- rda(multi2[,-c(1:4)] ~ location, data = multi_type)
  ordination_date <- rda(multi2[,-c(1:4)] ~ recording_date, data = multi_type)
  ordination_obs_loc <- rda(multi2[,-c(1:4)] ~ observer + location, data = multi_type)
  ordination_recording <- rda(multi2[,-c(1:4)] ~ location + recording_date, data = multi_type)
  ordination_obs_date <- rda(multi2[,-c(1:4)] ~ observer + recording_date, data = multi_type)
  
  # Getting R2 for models
  firstmodel <- RsquareAdj(ordination)$adj.r.squared
  obsmodel <- RsquareAdj(ordination_obs)$adj.r.squared
  locmodel <- RsquareAdj(ordination_loc)$adj.r.squared
  datemodel <- RsquareAdj(ordination_date)$adj.r.squared
  obs_plus_locmodel <- RsquareAdj(ordination_obs_loc)$adj.r.squared
  recordingmodel <- RsquareAdj(ordination_recording)$adj.r.squared
  obs_plus_datemodel <- RsquareAdj(ordination_obs_date)$adj.r.squared
  
  # Print the results of a permutation test for the constrained ordination
  step <- ordistep(ordination, direction = "both")
  u <- ordination$CCA$u %>% as.data.frame()
  
  showvarparts(2, bg = c("hotpink","skyblue"))
  # Partioning the variance of the RDA
  mod <- varpart(multi2[,-c(1:4)] %>% as.data.frame(), as.factor(multi2$location), as.factor(multi2$observer), transfo="hel")
  ## Use fill colours
  plot(mod, bg = c("hotpink","skyblue"))
  # Alternative way of to conduct this partitioning
  
  # Set up the output - scores first
  ordination_scores <- scores(ordination_obs, display = "sites") %>%
    as.data.frame() %>%
    rownames_to_column("site") %>%
    bind_cols(., multi_type)
  
  # Then eigenvectors 
  ordination_vect <- scores(ordination_obs, display = "species") %>%
    as.data.frame()
  
  # Now plot everything for the ordination
  plot_RDA <- ggplot(data = ordination_scores, aes(x = RDA1, y = RDA2)) +
    geom_point(data = ordination_scores, aes(x = RDA1, y = RDA2, colour = observer), alpha = 0.6) +
    stat_ellipse(data = ordination_scores, aes(colour = observer), linetype = 4, type = 'norm', level = 0.67) +
    geom_vline(xintercept = c(0), color = "#A19E99", linetype = 2) +
    geom_hline(yintercept = c(0), color = "#A19E99", linetype = 2) +
    geom_segment(data = ordination_vect, aes(x = 0, y = 0, xend = RDA1, yend = RDA2), arrow = arrow(length = unit(0.2, "cm"))) +
    geom_text(data = ordination_vect, aes(x = RDA1, y = RDA2, label = rownames(ordination_vect))) +
    # Apply ABMI themes
    labs(x = paste0("RDA1 ", round(ordination$CA$eig[[1]],2), '%'),
         y = paste0("RDA2 ", round(ordination$CA$eig[[2]],2), '%'),
         title = paste0("RDA of observer detections constrained by recording")) +
    theme_bw() +
    guides(fill="none") +
    scale_colour_viridis_d()
    
  
  # Time to first detection data setup
  dd <- data %>%
  select(location, recording_date, 
         observer, species_code, individual_appearance_order, 
         tag_start_s, tag_duration_s,  min_tag_freq, max_tag_freq, vocalization, abundance) %>%
  distinct() %>%
  group_by(location, recording_date) %>%
  mutate(unique_times = n_distinct(observer)) %>%
  ungroup() %>%
  filter(unique_times >= 11) %>%
  select(-unique_times) %>%
  relocate(abundance, .after=individual_appearance_order) %>%
  mutate_at(vars(min_tag_freq, max_tag_freq), ~as.numeric(str_replace(.,"kHz",""))) %>%
  group_by(location, recording_date, observer) %>%
  mutate(detection_order = row_number()) %>%
  ungroup() %>%
  mutate(freq_diff = max_tag_freq - min_tag_freq) %>%
  mutate(Unknown = case_when(grepl('^U',species_code) ~ "Unknown", TRUE ~ "Species"))
  
  # Plot the results
d <- ggplot(dd, aes(x=tag_start_s,y=detection_order,colour=Unknown,shape=Unknown)) +
  geom_point(alpha = 0.2) +
  geom_smooth(alpha = 0.6) +
  ylim(0,50) +
  facet_wrap(~observer, scales="free_x") +
  ggtitle("Time to first detection of species and unknown tags") +
  xlab("Tag start time (seconds)") + ylab("Detections per recording") +
  scale_colour_viridis_d() +
  theme_bw()

#Return all objects 
  return(list(plot_RDA, # Ordination
              d, # Time to first detection plot 
              ordination, # Ordination 
              ordination_scores %>% as_tibble(), # Ordination scores
              vegan::anova.cca(ordination, step = 1000, by = "term"), # Permutation Test for RDA (ANOVA-like)
              vegan::adonis(multi2[,-c(1:4)] ~ observer + location + recording_date, data = multi_type, distance = "jaccard"), # PERMANOVA
              vegan::adonis2(multi2[,-c(1:4)] ~ observer + location + recording_date, data = multi_type, distance = "jaccard")))
}

```

Now we run the function.

```{r, eval = T, include = T, warning = F, message = F}
# Using the most recent quality control
res <- wt_ord(input = data, min_obs = 11, confidence = 0.67)

```






## Time to first detection between observers

```{r}

res[[2]]


```

## False negative rates and use of BirdNET


```{r}
# Load and prepare the BirdNET data

fn <- dir_ls(path = "/users/alexandremacphail/desktop/qc", regexp = "*recording_birdnet.csv") %>%
  map(~read_csv(., col_types = list(location = col_character()))) %>%
  bind_rows()

nfn <- fn %>%
  filter(!window_start_time >= 180) %>%
  select(location, recording_date, scientific_name, window_start_time, confidence) %>%
  distinct() %>%
  inner_join(., cls %>% select(species_code, species_common_name, scientific_name), by = c("scientific_name" = "scientific_name")) %>%
  add_column(observer = "BirdNET") %>%
  add_column(project_name = "BirdNET Output") %>%
  select(project_name, location, recording_date, observer, species_code, window_start_time, confidence) %>%
  rename("tag_start_s" = 6) %>%
  mutate(tag_start_s = as.double(tag_start_s)) %>%
  add_column(abundance = "1")

data_bn <- bind_rows(data, nfn)

```




# Results

## Multivariate analysis of species detections


```{r, eval = T, include = T}

res[[1]] # Ordination

```

## Time to first detection between observers

```{r, warning = F, message = F}

res[[2]] # Time to first detection

```

## False negative rates and use of BirdNET

```{r}


```


# Discussion

## Steps to identify species identification errors

- Reproduce multiobs data
- Run `wt_ord` and identify obs

## Training, skill development and testing

- Training well
- Develop skills using results of multi-obs stuff
- Add to species verification half are 1/2 verified to learn
- Exam to make sure productivity, accuracy and precision is high

# References


