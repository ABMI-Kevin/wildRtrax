---
title: 'Acoustic pre-processing'
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Acoustic pre-processing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = '#>'
)

```

## Acoustic pre-processing

This vignette describes several acoustic pre-processing functions and work flows available in the `wildRtrax` package. 

### Scanning audio files from a directory

The `wt_audio_scanner()` function reads in audio files (either wac, wav or flac format) from a local directory and outputs useful metadata.

```{r setup, echo = F, include = T, warning = F, message = F}
# Attach packages
#library(wildRtrax)
#library(tidyverse)

```

```{r, include=F, eval=F, warning=F, message=F}
#save.image(".Data")

# Load example data from the wildRtrax book. Hide this block.
load("book.RData")

```

```{r, echo=TRUE, include=TRUE, eval=F, warning = F, message = F}
# Scan data
b <- wt_audio_scanner(path = root, file_type = "all", extra_cols = T)

```

```{r, echo=T, include=T, eval=F, warning=F, message=F, prompt=T, comment=""}
# View
head(b)
```

You might want to select recordings between certain times of day or year. 

```{r, eval=F}
library(tidyverse)
library(lubridate)

# Filter recordings based on criteria
b %>%
  mutate(hour = hour(recording_date_time)) %>%
  filter(julian == 176, 
         hour %in% c(4:8))

```

### Running the QUT Ecoacoustics AnalysisPrograms software on a wt_* standard data set

The `wt_run_ap()` function allows you to run the QUT Analysis Programs [(AP.exe)](https://ap.qut.ecoacoustics.info/) on your audio data. AP generates acoustic index values and false-colour spectrograms for each audio minute of data. Note that you must have the AP program installed on your computer. See more here [(Towsey et al., 2018)](https://researchoutput.csu.edu.au/ws/portalfiles/portal/28556441/28544328_Published_article.pdf). 

```{r echo=TRUE, include=T, eval=F, warning = F, message = F}
#Use the wt_* tibble to execute the AP on the files

wt_run_ap(x = my_files, output_dir = paste0(root, 'ap_outputs'), path_to_ap = '/where/you/store/AP')

```

The use `wt_glean_ap` to plot the acoustic index and LDFC results

```{r, echo=T, include=T, eval=F, warning=F, message, prompt=T, comment=""}

wt_glean_ap()

```

### Applying a limited amplitude filter

We can use the `wt_signal_level()` function to search for sounds that exceed a certain amplitude threshold. 

```{r echo=TRUE, include=TRUE, eval=F}
# Example audio file
path_to_file <- b$file_path[3]

# Run
s <- wt_signal_level(path = path_to_file, 
                     fmin = 5000, 
                     fmax = 10000, 
                     threshold = 20, 
                     channel = 'left', 
                     aggregate = 5)

# Return a list object, with parameters stored
str(s)

# We can view the output:
s['output']
# We have eleven detections that exceeded this threshold.

```

### Linking files to WildTrax

The function `wt_songscope_tags` reformats the output obtained from a wildlife acoustics songscope recognizer. This transformation involves converting the recognizer tags into tags that do not have a method type. This makes it possible to upload each hit as a tag in a task.

```{r, include = T, eval=F, warning=F, message=F, prompt="", prompt=T}
wt_songscope_tags()

```

Similarly, the function `wt_kaleidoscope_tags` performs the same reformatting process, but with Kaleidoscope instead. It is worth noting that this function targeted for sonic and ultrasonic species upload.

```{r, include = T, eval=F, warning=F, message=F}
wt_kaleidoscope_tags()

```

Make tasks at any time using a `wt_*` standard data set.

```{r, include = T, eval=F, warning=F, message=F}
wt_make_aru_tasks()

```
